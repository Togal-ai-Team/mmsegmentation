{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:/Users/kpazr/Desktop/base_model/mmsegmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "H8Fxg8i-wHJE"
   },
   "outputs": [],
   "source": [
    "from mmseg.apis import inference_segmentor, init_segmentor, show_result_pyplot\n",
    "from mmseg.core.evaluation import get_palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "umk8sJ0Xuace"
   },
   "outputs": [],
   "source": [
    "config_file = '../configs/togal_test/standard_unet.py'\n",
    "\n",
    "#config_file = '../configs/unet/fcn_unet_s5-d16_128x128_40k_stare.py'\n",
    "checkpoint_file = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nWlQFuTgudxu",
    "outputId": "5e45f4f6-5bcf-4d04-bb9c-0428ee84a576"
   },
   "outputs": [],
   "source": [
    "# build the model from a config file and a checkpoint file\n",
    "model = init_segmentor(config_file, checkpoint_file, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "izFv6pSRujk9"
   },
   "outputs": [],
   "source": [
    "# test a single image\n",
    "img = '../demo/demo.png'\n",
    "result = inference_segmentor(model, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6251324"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(model.backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "id": "bDcs9udgunQK",
    "outputId": "7c55f713-4085-47fd-fa06-720a321d0795"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1acdba8e0c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet(\n",
    "    encoder_name=\"efficientnet-b0\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=1,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=3,                      # model output channels (number of classes in your dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6251183"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ta51clKX4cwM"
   },
   "source": [
    "## Train a semantic segmentation model on a new dataset\n",
    "\n",
    "To train on a customized dataset, the following steps are neccessary. \n",
    "1. Add a new dataset class. \n",
    "2. Create a config file accordingly. \n",
    "3. Perform training and evaluation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AcZg6x_K5Zs3"
   },
   "source": [
    "### Add a new dataset\n",
    "\n",
    "Datasets in MMSegmentation require image and semantic segmentation maps to be placed in folders with the same perfix. To support a new dataset, we may need to modify the original file structure. \n",
    "\n",
    "In this tutorial, we give an example of converting the dataset. You may refer to [docs](https://github.com/open-mmlab/mmsegmentation/docs/tutorials/new_dataset.md) for details about dataset reorganization. \n",
    "\n",
    "We use [Standord Background Dataset](http://dags.stanford.edu/projects/scenedataset.html) as an example. The dataset contains 715 images chosen from existing public datasets [LabelMe](http://labelme.csail.mit.edu), [MSRC](http://research.microsoft.com/en-us/projects/objectclassrecognition), [PASCAL VOC](http://pascallin.ecs.soton.ac.uk/challenges/VOC) and [Geometric Context](http://www.cs.illinois.edu/homes/dhoiem/). Images from these datasets are mainly outdoor scenes, each containing approximately 320-by-240 pixels. \n",
    "In this tutorial, we use the region annotations as labels. There are 8 classes in total, i.e. sky, tree, road, grass, water, building, mountain, and foreground object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TFIt7MHq5Wls",
    "outputId": "74a126e4-c8a4-4d2f-a910-b58b71843a23"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "tar: Error opening archive: Failed to open 'standford_background.tar.gz'\n"
     ]
    }
   ],
   "source": [
    "# download and unzip\n",
    "!wget http://dags.stanford.edu/data/iccv09Data.tar.gz -O standford_background.tar.gz\n",
    "!tar xf standford_background.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "id": "78LIci7F9WWI",
    "outputId": "c432ddac-5a50-47b1-daac-5a26b07afea2"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "img file does not exist: iccv09Data/images/6000124.jpg",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2024/1076716656.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmmcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'iccv09Data/images/6000124.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmmcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbgr2rgb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\open-mmlab\\lib\\site-packages\\mmcv\\image\\io.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(img_or_path, flag, channel_order, backend)\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_or_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         check_file_exist(img_or_path,\n\u001b[1;32m--> 177\u001b[1;33m                          f'img file does not exist: {img_or_path}')\n\u001b[0m\u001b[0;32m    178\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'turbojpeg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0min_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\open-mmlab\\lib\\site-packages\\mmcv\\utils\\path.py\u001b[0m in \u001b[0;36mcheck_file_exist\u001b[1;34m(filename, msg_tmpl)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcheck_file_exist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_tmpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'file \"{}\" does not exist'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mosp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_tmpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: img file does not exist: iccv09Data/images/6000124.jpg"
     ]
    }
   ],
   "source": [
    "# Let's take a look at the dataset\n",
    "import mmcv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = mmcv.imread('iccv09Data/images/6000124.jpg')\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(mmcv.bgr2rgb(img))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5mNQuc2GsVE"
   },
   "source": [
    "We need to convert the annotation into semantic map format as an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WnGZfribFHCx"
   },
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "# convert dataset annotation to semantic segmentation map\n",
    "data_root = 'iccv09Data'\n",
    "img_dir = 'images'\n",
    "ann_dir = 'labels'\n",
    "# define class and plaette for better visualization\n",
    "classes = ('sky', 'tree', 'road', 'grass', 'water', 'bldg', 'mntn', 'fg obj')\n",
    "palette = [[128, 128, 128], [129, 127, 38], [120, 69, 125], [53, 125, 34], \n",
    "           [0, 11, 123], [118, 20, 12], [122, 81, 25], [241, 134, 51]]\n",
    "for file in mmcv.scandir(osp.join(data_root, ann_dir), suffix='.regions.txt'):\n",
    "  seg_map = np.loadtxt(osp.join(data_root, ann_dir, file)).astype(np.uint8)\n",
    "  seg_img = Image.fromarray(seg_map).convert('P')\n",
    "  seg_img.putpalette(np.array(palette, dtype=np.uint8))\n",
    "  seg_img.save(osp.join(data_root, ann_dir, file.replace('.regions.txt', \n",
    "                                                         '.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "id": "5MCSS9ABfSks",
    "outputId": "92b9bafc-589e-48fc-c9e9-476f125d6522"
   },
   "outputs": [],
   "source": [
    "# Let's take a look at the segmentation map we got\n",
    "import matplotlib.patches as mpatches\n",
    "img = Image.open('iccv09Data/labels/6000124.png')\n",
    "plt.figure(figsize=(8, 6))\n",
    "im = plt.imshow(np.array(img.convert('RGB')))\n",
    "\n",
    "# create a patch (proxy artist) for every color \n",
    "patches = [mpatches.Patch(color=np.array(palette[i])/255., \n",
    "                          label=classes[i]) for i in range(8)]\n",
    "# put those patched as legend-handles into the legend\n",
    "plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., \n",
    "           fontsize='large')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WbeLYCp2k5hl"
   },
   "outputs": [],
   "source": [
    "# split train/val set randomly\n",
    "split_dir = 'splits'\n",
    "mmcv.mkdir_or_exist(osp.join(data_root, split_dir))\n",
    "filename_list = [osp.splitext(filename)[0] for filename in mmcv.scandir(\n",
    "    osp.join(data_root, ann_dir), suffix='.png')]\n",
    "with open(osp.join(data_root, split_dir, 'train.txt'), 'w') as f:\n",
    "  # select first 4/5 as train set\n",
    "  train_length = int(len(filename_list)*4/5)\n",
    "  f.writelines(line + '\\n' for line in filename_list[:train_length])\n",
    "with open(osp.join(data_root, split_dir, 'val.txt'), 'w') as f:\n",
    "  # select last 1/5 as train set\n",
    "  f.writelines(line + '\\n' for line in filename_list[train_length:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HchvmGYB_rrO"
   },
   "source": [
    "After downloading the data, we need to implement `load_annotations` function in the new dataset class `StandfordBackgroundDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LbsWOw62_o-X"
   },
   "outputs": [],
   "source": [
    "from mmseg.datasets.builder import DATASETS\n",
    "from mmseg.datasets.custom import CustomDataset\n",
    "\n",
    "@DATASETS.register_module()\n",
    "class StandfordBackgroundDataset(CustomDataset):\n",
    "  CLASSES = classes\n",
    "  PALETTE = palette\n",
    "  def __init__(self, split, **kwargs):\n",
    "    super().__init__(img_suffix='.jpg', seg_map_suffix='.png', \n",
    "                     split=split, **kwargs)\n",
    "    assert osp.exists(self.img_dir) and self.split is not None\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUVtmn3Iq3WA"
   },
   "source": [
    "### Create a config file\n",
    "In the next step, we need to modify the config for the training. To accelerate the process, we finetune the model from trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wwnj9tRzqX_A"
   },
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "cfg = Config.fromfile('configs/pspnet/pspnet_r50-d8_512x1024_40k_cityscapes.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1y2oV5w97jQo"
   },
   "source": [
    "Since the given config is used to train PSPNet on cityscapes dataset, we need to modify it accordingly for our new dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyKnYC1Z7iCV",
    "outputId": "6195217b-187f-4675-994b-ba90d8bb3078"
   },
   "outputs": [],
   "source": [
    "from mmseg.apis import set_random_seed\n",
    "\n",
    "# Since we use ony one GPU, BN is used instead of SyncBN\n",
    "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
    "cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n",
    "# modify num classes of the model in decode/auxiliary head\n",
    "cfg.model.decode_head.num_classes = 8\n",
    "cfg.model.auxiliary_head.num_classes = 8\n",
    "\n",
    "# Modify dataset type and path\n",
    "cfg.dataset_type = 'StandfordBackgroundDataset'\n",
    "cfg.data_root = data_root\n",
    "\n",
    "cfg.data.samples_per_gpu = 8\n",
    "cfg.data.workers_per_gpu=8\n",
    "\n",
    "cfg.img_norm_cfg = dict(\n",
    "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "cfg.crop_size = (256, 256)\n",
    "cfg.train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations'),\n",
    "    dict(type='Resize', img_scale=(320, 240), ratio_range=(0.5, 2.0)),\n",
    "    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
    "    dict(type='RandomFlip', flip_ratio=0.5),\n",
    "    dict(type='PhotoMetricDistortion'),\n",
    "    dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "    dict(type='Pad', size=cfg.crop_size, pad_val=0, seg_pad_val=255),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n",
    "]\n",
    "\n",
    "cfg.test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=(320, 240),\n",
    "        # img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='Resize', keep_ratio=True),\n",
    "            dict(type='RandomFlip'),\n",
    "            dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='Collect', keys=['img']),\n",
    "        ])\n",
    "]\n",
    "\n",
    "\n",
    "cfg.data.train.type = cfg.dataset_type\n",
    "cfg.data.train.data_root = cfg.data_root\n",
    "cfg.data.train.img_dir = img_dir\n",
    "cfg.data.train.ann_dir = ann_dir\n",
    "cfg.data.train.pipeline = cfg.train_pipeline\n",
    "cfg.data.train.split = 'splits/train.txt'\n",
    "\n",
    "cfg.data.val.type = cfg.dataset_type\n",
    "cfg.data.val.data_root = cfg.data_root\n",
    "cfg.data.val.img_dir = img_dir\n",
    "cfg.data.val.ann_dir = ann_dir\n",
    "cfg.data.val.pipeline = cfg.test_pipeline\n",
    "cfg.data.val.split = 'splits/val.txt'\n",
    "\n",
    "cfg.data.test.type = cfg.dataset_type\n",
    "cfg.data.test.data_root = cfg.data_root\n",
    "cfg.data.test.img_dir = img_dir\n",
    "cfg.data.test.ann_dir = ann_dir\n",
    "cfg.data.test.pipeline = cfg.test_pipeline\n",
    "cfg.data.test.split = 'splits/val.txt'\n",
    "\n",
    "# We can still use the pre-trained Mask RCNN model though we do not need to\n",
    "# use the mask branch\n",
    "cfg.load_from = 'checkpoints/pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './work_dirs/tutorial'\n",
    "\n",
    "cfg.runner.max_iters = 200\n",
    "cfg.log_config.interval = 10\n",
    "cfg.evaluation.interval = 200\n",
    "cfg.checkpoint_config.interval = 200\n",
    "\n",
    "# Set seed to facitate reproducing the result\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "# Let's have a look at the final config used for training\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWuH14LYF2gQ"
   },
   "source": [
    "### Train and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jYKoSfdMF12B",
    "outputId": "422219ca-d7a5-4890-f09f-88c959942e64"
   },
   "outputs": [],
   "source": [
    "from mmseg.datasets import build_dataset\n",
    "from mmseg.models import build_segmentor\n",
    "from mmseg.apis import train_segmentor\n",
    "\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the detector\n",
    "model = build_segmentor(\n",
    "    cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_segmentor(model, datasets, cfg, distributed=False, validate=True, \n",
    "                meta=dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEkWOP-NMbc_"
   },
   "source": [
    "Inference with trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 645
    },
    "id": "ekG__UfaH_OU",
    "outputId": "1437419c-869a-4902-df86-d4f6f8b2597a"
   },
   "outputs": [],
   "source": [
    "img = mmcv.imread('iccv09Data/images/6000124.jpg')\n",
    "\n",
    "model.cfg = cfg\n",
    "result = inference_segmentor(model, img)\n",
    "plt.figure(figsize=(8, 6))\n",
    "show_result_pyplot(model, img, result, palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "MMSegmentation Tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
